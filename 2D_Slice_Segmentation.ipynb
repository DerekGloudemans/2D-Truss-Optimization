{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2D Slice Segmentation",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyM8nqxzbYrdYIUW+impJQRO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DerekGloudemans/2D-Truss-Optimization/blob/master/2D_Slice_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWuPYaAANe9r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 126
        },
        "outputId": "60016978-891d-4ab8-8343-aef8eb14f2c5"
      },
      "source": [
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_qqHuf8NN6hw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "556eaada-ed52-477b-9e0f-e61616227103"
      },
      "source": [
        "#%%capture \n",
        "!pip install -q --upgrade ipython==5.5.0\n",
        "!pip install -q --upgrade ipykernel==4.6.0\n",
        "!pip3 install torchvision\n",
        "!pip3 install opencv-python\n",
        "\n",
        "#!pip uninstall torch -y\n",
        "#!pip install --pre torch torchvision -f https://download.pytorch.org/whl/nightly/cu100/torch_nightly.html\n",
        "\n",
        "import ipywidgets\n",
        "import traitlets\n",
        "\n",
        "#!pip3 install filterpy\n",
        "#!pip3 install opencv-contrib-python"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |███▏                            | 10kB 25.0MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |█████████▍                      | 30kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 40kB 1.7MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 51kB 2.1MB/s eta 0:00:01\r\u001b[K     |██████████████████▉             | 61kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 71kB 2.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▏      | 81kB 3.3MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 92kB 3.7MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▍| 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 112kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: torchvision in /usr/local/lib/python3.6/dist-packages (0.5.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.12.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.17.5)\n",
            "Requirement already satisfied: torch==1.4.0 in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.4.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.6/dist-packages (from torchvision) (6.2.2)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.6/dist-packages (4.1.2.30)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from opencv-python) (1.17.5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dAi-OI1_N65G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports\n",
        "\n",
        "# this seems to be a popular thing to do so I've done it here\n",
        "#from __future__ import print_function, division\n",
        "\n",
        "\n",
        "# torch and specific torch packages for convenience\n",
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "from torch.utils import data\n",
        "from torch import multiprocessing\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "# for convenient data loading, image representation and dataset management\n",
        "from torchvision import models, transforms\n",
        "from PIL import Image, ImageFile, ImageStat\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
        "from scipy.ndimage import affine_transform\n",
        "import cv2\n",
        "\n",
        "# always good to have\n",
        "import time\n",
        "import os\n",
        "import numpy as np    \n",
        "import _pickle as pickle\n",
        "import random\n",
        "import copy\n",
        "import matplotlib.pyplot as plt\n",
        "import math\n",
        "\n",
        "import nibabel as nib\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3oGORnSYOTan",
        "colab_type": "text"
      },
      "source": [
        "## Define Dataset for Dealing with NIfTI Files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PxDtlv1qfaoB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Nifti_Dataset(data.Dataset):\n",
        "  def __init__(self,mode = \"train\"):\n",
        "    \"\"\"\n",
        "    Save the last 0.15 proportion of files after sorting for use as validation set.\n",
        "    Loads each slice of the input images as a separate image\n",
        "    \"\"\"\n",
        "    self.mode = mode\n",
        "    data_dir = \"/content/drive/My Drive/Colab Notebooks/Segmentation/train_data\"\n",
        "    label_dir = \"/content/drive/My Drive/Colab Notebooks/Segmentation/train_labels\"\n",
        "\n",
        "    # get all data and label file names\n",
        "    self.data_files = []\n",
        "    for file in os.listdir(data_dir):\n",
        "      self.data_files.append(os.path.join(data_dir,file))\n",
        "    self.data_files.sort()\n",
        "\n",
        "    self.label_files = []\n",
        "    for file in os.listdir(label_dir):\n",
        "      self.label_files.append(os.path.join(label_dir,file))\n",
        "    self.label_files.sort()\n",
        "\n",
        "    # for each data_file\n",
        "    self.train_data = []\n",
        "    self.val_data = []\n",
        "\n",
        "    for i in range(len(self.data_files)):\n",
        "      data = nib.load(self.data_files[i])\n",
        "      data = np.array(data.get_fdata())\n",
        "\n",
        "      label = nib.load(self.label_files[i])\n",
        "      label = np.array(label.get_fdata())\n",
        "\n",
        "      identifier = self.data_files[i].split(\"_\")[0]\n",
        "\n",
        "      for slice in range(0,data.shape[2]):\n",
        "        item = {\n",
        "            \"identifier\":identifier,\n",
        "            \"slice\":slice,\n",
        "            \"data\":data[:,:,slice],\n",
        "            \"label\":label[:,:,slice]\n",
        "                }\n",
        "        if i < len(self.data_files) * 0.85:\n",
        "          self.train_data.append(item)\n",
        "        else:\n",
        "          self.val_data.append(item)\n",
        "\n",
        "  def __getitem__(self,index):\n",
        "      \n",
        "  def __len(self):\n",
        "    if self.mode == \"train\":\n",
        "      return len(self.train_data)\n",
        "    else:\n",
        "      return len(self.val_data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMcEpD5uPFEx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset = Nifti_Dataset()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SAXv15t6oAl7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "outputId": "526ee58e-69ce-4a03-ad53-b3a5dbc234f7"
      },
      "source": [
        ""
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-46-ff8b411b8b5c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
          ]
        }
      ]
    }
  ]
}